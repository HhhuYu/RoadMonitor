{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-06T16:52:11.423235Z",
     "start_time": "2020-07-06T16:52:11.416215Z"
    }
   },
   "outputs": [],
   "source": [
    "from siml.sk_utils import *\n",
    "from siml.signal_analysis_utils import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import scipy.stats\n",
    "import pandas as pd\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from detecta import detect_peaks\n",
    "from scipy.fftpack import fft\n",
    "from scipy.signal import welch\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载数据文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-06T16:52:11.445884Z",
     "start_time": "2020-07-06T16:52:11.440898Z"
    }
   },
   "outputs": [],
   "source": [
    "typeDescription = {\n",
    "    0: 'normal',\n",
    "    1: 'pothole',\n",
    "    2: 'transverse',\n",
    "}\n",
    "\n",
    "\n",
    "def readFile(filename):\n",
    "    return np.loadtxt(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-06T16:52:11.600512Z",
     "start_time": "2020-07-06T16:52:11.448876Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集： (899, 64, 3)\n",
      "{'normal': 817, 'pothole': 69, 'transverse': 13}\n"
     ]
    }
   ],
   "source": [
    "folderPath = '../../data/Final_Version/poor/datasets/'\n",
    "dataFile = ['dataX.txt', 'dataY.txt', 'dataZ.txt']\n",
    "labelFile = ['dataLabel.txt']\n",
    "\n",
    "signals = []\n",
    "for file in dataFile:\n",
    "    dataPath = folderPath+file\n",
    "    signals.append(np.loadtxt(dataPath))\n",
    "signals = np.transpose(np.array(signals), (1, 2, 0))\n",
    "print('数据集：', signals.shape)\n",
    "\n",
    "labelFilePath = folderPath+labelFile[0]\n",
    "dataLabel = np.loadtxt(labelFilePath)\n",
    "anomalyType = list(dataLabel[:, 0])\n",
    "\n",
    "dic = {}\n",
    "temp = Counter(anomalyType)\n",
    "for key in temp.keys():\n",
    "    dic[typeDescription[key]] = temp[key]\n",
    "print(dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-06T16:52:11.609446Z",
     "start_time": "2020-07-06T16:52:11.602465Z"
    }
   },
   "outputs": [],
   "source": [
    "N = 64 #样本数\n",
    "f_s = 50 #采样频率\n",
    "denominator = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-06T16:52:11.622412Z",
     "start_time": "2020-07-06T16:52:11.612440Z"
    }
   },
   "outputs": [],
   "source": [
    "#FFT\n",
    "def get_fft_values(y_values, N, f_s):\n",
    "    f_values = np.linspace(0.0, f_s/2.0, N//2)\n",
    "    fft_values_ = fft(y_values)\n",
    "    fft_values = 2.0/N * np.abs(fft_values_[0:N//2])\n",
    "    return fft_values\n",
    "\n",
    "#PSD\n",
    "def get_psd_values(y_values, N, f_s):\n",
    "    f_values, psd_values = welch(y_values, fs=f_s)\n",
    "    return  psd_values\n",
    "\n",
    "#Autocorrelation\n",
    "def autocorr(x):\n",
    "    result = np.correlate(x, x, mode='full')\n",
    "    return result[len(result)//2:]\n",
    " \n",
    "def get_autocorr_values(y_values, N, f_s):\n",
    "    autocorr_values = autocorr(y_values)\n",
    "    x_values = np.array([ 1.0*jj/f_s for jj in range(0, N)])\n",
    "    return autocorr_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-06T16:52:11.643396Z",
     "start_time": "2020-07-06T16:52:11.625405Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_entropy(list_values):\n",
    "    counter_values = Counter(list_values).most_common()\n",
    "    # print(counter_values)\n",
    "    probabilities = [elem[1]/len(list_values) for elem in counter_values]\n",
    "    # print(probabilities)\n",
    "    entropy = scipy.stats.entropy(probabilities)\n",
    "    return entropy\n",
    "\n",
    "\n",
    "def calculate_statistics(list_values):\n",
    "    n5 = np.nanpercentile(list_values, 5)\n",
    "    n25 = np.nanpercentile(list_values, 25)\n",
    "    n75 = np.nanpercentile(list_values, 75)\n",
    "    n95 = np.nanpercentile(list_values, 95)\n",
    "    median = np.nanpercentile(list_values, 50)\n",
    "    mean = np.nanmean(list_values)\n",
    "    std = np.nanstd(list_values)\n",
    "    var = np.nanvar(list_values)\n",
    "    rms = np.nanmean(np.sqrt(list_values**2))\n",
    "    return [n5, n25, n75, n95, median, mean, std, var, rms]\n",
    "\n",
    "\n",
    "def calculate_crossings(list_values):\n",
    "    zero_crossing_indices = np.nonzero(np.diff(np.array(list_values) > 0))[0]\n",
    "    no_zero_crossings = len(zero_crossing_indices)\n",
    "    mean_crossing_indices = np.nonzero(\n",
    "        np.diff(np.array(list_values) > np.nanmean(list_values)))[0]\n",
    "    no_mean_crossings = len(mean_crossing_indices)\n",
    "    return [no_zero_crossings, no_mean_crossings]\n",
    "\n",
    "\n",
    "def get_features(list_values):\n",
    "    entropy = calculate_entropy(list_values)\n",
    "    crossings = calculate_crossings(list_values)\n",
    "    statistics = calculate_statistics(list_values)\n",
    "    return [entropy] + crossings + statistics\n",
    "\n",
    "\n",
    "def extract_features(dataset, N, f_s):\n",
    "    uci_har_features = []\n",
    "    for signal_no in range(0, len(dataset)):\n",
    "        features = []\n",
    "        for signal_comp in range(0, dataset.shape[2]):\n",
    "            signal = dataset[signal_no, :, signal_comp]\n",
    "            features += get_features(get_fft_values(signal, N, f_s))\n",
    "            features += get_features(get_psd_values(signal, N, f_s))\n",
    "            features += get_features(get_autocorr_values(signal, N, f_s))\n",
    "        uci_har_features.append(features)\n",
    "    X = np.array(uci_har_features)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-06T16:52:19.323007Z",
     "start_time": "2020-07-06T16:52:11.645352Z"
    }
   },
   "outputs": [],
   "source": [
    "features = extract_features(\n",
    "    signals, N, f_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-06T16:52:19.328932Z",
     "start_time": "2020-07-06T16:52:19.324942Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(899, 108)\n"
     ]
    }
   ],
   "source": [
    "print(features.shape)\n",
    "labels = np.array(anomalyType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-06T16:52:19.347923Z",
     "start_time": "2020-07-06T16:52:19.331452Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0358157 , 0.        , 0.12401073, ..., 0.08874499, 0.76209604,\n",
       "        0.05263877],\n",
       "       [0.03766885, 0.        , 0.10868932, ..., 0.0828915 , 0.63216888,\n",
       "        0.04230999],\n",
       "       [0.04766855, 0.        , 0.11003388, ..., 0.07136573, 0.37029087,\n",
       "        0.03298544],\n",
       "       ...,\n",
       "       [0.0196663 , 0.        , 0.04539596, ..., 0.07192155, 0.91157172,\n",
       "        0.03447181],\n",
       "       [0.04231993, 0.        , 0.1709533 , ..., 0.08888996, 0.64707703,\n",
       "        0.06150929],\n",
       "       [0.04368873, 0.        , 0.12605902, ..., 0.08366314, 0.55525747,\n",
       "        0.04820655]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StandardScaler().fit_transform(features)\n",
    "Normalizer().fit_transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 信号分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-06T16:52:19.356899Z",
     "start_time": "2020-07-06T16:52:19.349916Z"
    }
   },
   "outputs": [],
   "source": [
    "def randomize(features, labels):\n",
    "    permutation = np.random.permutation(labels.shape[0])\n",
    "    shuffled_features = features[permutation, :]\n",
    "    shuffled_labels = labels[permutation]\n",
    "    return shuffled_features, shuffled_labels\n",
    "\n",
    "iteration = 100\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-06T16:52:24.739790Z",
     "start_time": "2020-07-06T16:52:19.358891Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of Logistic Regression\n",
      "Accuracy on training set is : 0.943370429252782\n",
      "Accuracy on test set is : 0.9267777777777779\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.950     0.982     0.966     24524\n",
      "         1.0      0.611     0.435     0.509      2099\n",
      "         2.0      0.176     0.069     0.099       377\n",
      "\n",
      "    accuracy                          0.927     27000\n",
      "   macro avg      0.579     0.495     0.524     27000\n",
      "weighted avg      0.913     0.927     0.918     27000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yTest, yPredict = [], []\n",
    "trainingScore, testingScore = 0, 0\n",
    "for i in range(iteration):\n",
    "    X, Y = randomize(features,labels)\n",
    "    X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.3,random_state=0)\n",
    "    clf = LogisticRegression(random_state=0)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    Y_test_pred = clf.predict(X_test)\n",
    "    yTest.extend(Y_test)\n",
    "    yPredict.extend(Y_test_pred)\n",
    "    trainingScore += clf.score(X_train, Y_train)\n",
    "    testingScore += clf.score(X_test, Y_test)\n",
    "print(\"Results of Logistic Regression\")\n",
    "print(\"Accuracy on training set is : {}\".format(trainingScore/iteration))\n",
    "print(\"Accuracy on test set is : {}\".format(testingScore/iteration))\n",
    "print(classification_report(yTest, yPredict,digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-06T16:52:27.646903Z",
     "start_time": "2020-07-06T16:52:24.740787Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of Support Vector Machine\n",
      "Accuracy on training set is : 0.9315739268680442\n",
      "Accuracy on test set is : 0.9307407407407411\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.937     0.997     0.966     24557\n",
      "         1.0      0.753     0.320     0.449      2053\n",
      "         2.0      0.000     0.000     0.000       390\n",
      "\n",
      "    accuracy                          0.931     27000\n",
      "   macro avg      0.563     0.439     0.472     27000\n",
      "weighted avg      0.909     0.931     0.912     27000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yTest, yPredict = [], []\n",
    "trainingScore, testingScore = 0, 0\n",
    "for i in range(iteration):\n",
    "    X, Y = randomize(features,labels)\n",
    "    X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.3,random_state=0)\n",
    "    clf = svm.SVC()\n",
    "    clf.fit(X_train, Y_train)\n",
    "    Y_test_pred = clf.predict(X_test)\n",
    "    yTest.extend(Y_test)\n",
    "    yPredict.extend(Y_test_pred)\n",
    "    trainingScore += clf.score(X_train, Y_train)\n",
    "    testingScore += clf.score(X_test, Y_test)\n",
    "print(\"Results of Support Vector Machine\")  \n",
    "print(\"Accuracy on training set is : {}\".format(trainingScore/iteration))\n",
    "print(\"Accuracy on test set is : {}\".format(testingScore/iteration))\n",
    "print(classification_report(yTest, yPredict,digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-06T16:53:01.065872Z",
     "start_time": "2020-07-06T16:52:27.647899Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of RandomForest\n",
      "Accuracy on training set is : 0.9999523052464228\n",
      "Accuracy on test set is : 0.9363703703703709\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.952     0.988     0.970     24553\n",
      "         1.0      0.673     0.505     0.577      2023\n",
      "         2.0      0.000     0.000     0.000       424\n",
      "\n",
      "    accuracy                          0.936     27000\n",
      "   macro avg      0.542     0.498     0.516     27000\n",
      "weighted avg      0.917     0.936     0.925     27000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yTest, yPredict = [], []\n",
    "trainingScore, testingScore = 0, 0\n",
    "for i in range(iteration):\n",
    "    X, Y = randomize(features,labels)\n",
    "    X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.3,random_state=0)\n",
    "    clf = RandomForestClassifier(n_estimators=100)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    Y_test_pred = clf.predict(X_test)\n",
    "    yTest.extend(Y_test)\n",
    "    yPredict.extend(Y_test_pred)\n",
    "    trainingScore += clf.score(X_train, Y_train)\n",
    "    testingScore += clf.score(X_test, Y_test)\n",
    "print(\"Results of RandomForest\")\n",
    "print(\"Accuracy on training set is : {}\".format(trainingScore/iteration))\n",
    "print(\"Accuracy on test set is : {}\".format(testingScore/iteration))\n",
    "print(classification_report(yTest, yPredict,digits=3))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
