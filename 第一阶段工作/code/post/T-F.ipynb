{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T07:01:54.452597Z",
     "start_time": "2020-07-13T07:01:54.442577Z"
    }
   },
   "outputs": [],
   "source": [
    "from siml.sk_utils import *\n",
    "from siml.signal_analysis_utils import *\n",
    "import numpy as np\n",
    "import pywt\n",
    "import scipy.stats\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载数据文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T07:01:54.476772Z",
     "start_time": "2020-07-13T07:01:54.472781Z"
    }
   },
   "outputs": [],
   "source": [
    "typeDescription = {\n",
    "    0: 'normal',\n",
    "    1: 'pothole',\n",
    "    2: 'transverse',\n",
    "}\n",
    "\n",
    "\n",
    "def readFile(filename):\n",
    "    return np.loadtxt(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T07:01:55.117093Z",
     "start_time": "2020-07-13T07:01:54.478766Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集： (4088, 64, 3)\n",
      "{'normal': 3601, 'pothole': 474, 'transverse': 13}\n"
     ]
    }
   ],
   "source": [
    "folderPath = '../../data/Final_Version/all/datasets/'\n",
    "dataFile = ['dataX.txt', 'dataY.txt', 'dataZ.txt']\n",
    "labelFile = ['dataLabel.txt']\n",
    "\n",
    "signals = []\n",
    "for file in dataFile:\n",
    "    dataPath = folderPath+file\n",
    "    signals.append(np.loadtxt(dataPath))\n",
    "signals = np.transpose(np.array(signals), (1, 2, 0))\n",
    "print('数据集：', signals.shape)\n",
    "\n",
    "labelFilePath = folderPath+labelFile[0]\n",
    "dataLabel = np.loadtxt(labelFilePath)\n",
    "anomalyType = list(dataLabel[:, 0])\n",
    "\n",
    "dic = {}\n",
    "temp = Counter(anomalyType)\n",
    "for key in temp.keys():\n",
    "    dic[typeDescription[key]] = temp[key]\n",
    "print(dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征提取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 时域特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T07:01:55.130055Z",
     "start_time": "2020-07-13T07:01:55.119053Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_entropy(list_values):\n",
    "    counter_values = Counter(list_values).most_common()\n",
    "    # print(counter_values)\n",
    "    probabilities = [elem[1]/len(list_values) for elem in counter_values]\n",
    "    # print(probabilities)\n",
    "    entropy = scipy.stats.entropy(probabilities)\n",
    "    return entropy\n",
    "\n",
    "\n",
    "def calculate_statistics(list_values):\n",
    "    n5 = np.nanpercentile(list_values, 5)\n",
    "    n25 = np.nanpercentile(list_values, 25)\n",
    "    n75 = np.nanpercentile(list_values, 75)\n",
    "    n95 = np.nanpercentile(list_values, 95)\n",
    "    median = np.nanpercentile(list_values, 50)\n",
    "    mean = np.nanmean(list_values)\n",
    "    std = np.nanstd(list_values)\n",
    "    var = np.nanvar(list_values)\n",
    "    rms = np.nanmean(np.sqrt(list_values**2))\n",
    "    return [n5, n25, n75, n95, median, mean, std, var, rms]\n",
    "\n",
    "\n",
    "def calculate_crossings(list_values):\n",
    "    zero_crossing_indices = np.nonzero(np.diff(np.array(list_values) > 0))[0]\n",
    "    no_zero_crossings = len(zero_crossing_indices)\n",
    "    mean_crossing_indices = np.nonzero(\n",
    "        np.diff(np.array(list_values) > np.nanmean(list_values)))[0]\n",
    "    no_mean_crossings = len(mean_crossing_indices)\n",
    "    return [no_zero_crossings, no_mean_crossings]\n",
    "\n",
    "\n",
    "def get_features1(list_values):\n",
    "    entropy = calculate_entropy(list_values)\n",
    "    crossings = calculate_crossings(list_values)\n",
    "    statistics = calculate_statistics(list_values)\n",
    "    return [entropy] + crossings + statistics\n",
    "\n",
    "\n",
    "def extract_features1(dataset):\n",
    "    uci_har_features = []\n",
    "    for signal_no in range(0, len(dataset)):\n",
    "        features = []\n",
    "        for signal_comp in range(0, dataset.shape[2]):\n",
    "            signal = dataset[signal_no, :, signal_comp]\n",
    "            features += get_features1(signal)\n",
    "        uci_har_features.append(features)\n",
    "    X = np.array(uci_har_features)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T07:02:05.496076Z",
     "start_time": "2020-07-13T07:01:55.132019Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "features1 = extract_features1(signals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 频域特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T07:02:05.507013Z",
     "start_time": "2020-07-13T07:02:05.498064Z"
    }
   },
   "outputs": [],
   "source": [
    "#FFT\n",
    "def get_fft_values(y_values, N, f_s):\n",
    "    f_values = np.linspace(0.0, f_s/2.0, N//2)\n",
    "    fft_values_ = fft(y_values)\n",
    "    fft_values = 2.0/N * np.abs(fft_values_[0:N//2])\n",
    "    return f_values, fft_values\n",
    "\n",
    "#PSD\n",
    "def get_psd_values(y_values, N, f_s):\n",
    "    f_values, psd_values = welch(y_values, fs=f_s)\n",
    "    return f_values, psd_values\n",
    "\n",
    "#Autocorrelation\n",
    "def autocorr(x):\n",
    "    result = np.correlate(x, x, mode='full')\n",
    "    return result[len(result)//2:]\n",
    " \n",
    "def get_autocorr_values(y_values, N, f_s):\n",
    "    autocorr_values = autocorr(y_values)\n",
    "    x_values = np.array([ 1.0*jj/f_s for jj in range(0, N)])\n",
    "    return x_values, autocorr_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T07:02:05.522968Z",
     "start_time": "2020-07-13T07:02:05.509006Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_first_n_peaks(x, y, no_peaks=5):\n",
    "    x_, y_ = list(x), list(y)\n",
    "    if len(x_) >= no_peaks:\n",
    "        ans = np.argsort(y)[-5:]\n",
    "        ans = ans[np.argsort(ans)]\n",
    "        return list(x[ans]), list(y[ans])\n",
    "        # return x_[:no_peaks], y_[:no_peaks]\n",
    "    else:  # 少于5个peaks，以0填充\n",
    "        missing_no_peaks = no_peaks-len(x_)\n",
    "        return x_ + [0]*missing_no_peaks, y_ + [0]*missing_no_peaks\n",
    "\n",
    "\n",
    "def get_features2(x_values, y_values, mph):\n",
    "    indices_peaks = detect_peaks(y_values, mph=mph)\n",
    "    peaks_x, peaks_y = get_first_n_peaks(\n",
    "        x_values[indices_peaks], y_values[indices_peaks])\n",
    "    return peaks_x + peaks_y\n",
    "\n",
    "\n",
    "def extract_features2(dataset, N, f_s, denominator):\n",
    "    percentile = 5\n",
    "    list_of_features = []\n",
    "\n",
    "    for signal_no in range(0, len(dataset)):\n",
    "        features = []  # 5*2*3*3\n",
    "\n",
    "        for signal_comp in range(0, dataset.shape[2]):\n",
    "            signal = dataset[signal_no, :, signal_comp]\n",
    "\n",
    "            signal_min = np.nanpercentile(signal, percentile)\n",
    "            signal_max = np.nanpercentile(signal, 100-percentile)\n",
    "            #ijk = (100 - 2*percentile)/10\n",
    "            # set minimum peak height\n",
    "            #mph = signal_min + (signal_max - signal_min)/denominator\n",
    "            mph = signal_min\n",
    "\n",
    "            features += get_features2(*get_psd_values(signal, N, f_s), mph)\n",
    "            features += get_features2(*get_fft_values(signal, N, f_s), mph)\n",
    "            features += get_features2(*\n",
    "                                     get_autocorr_values(signal, N, f_s), mph)\n",
    "        list_of_features.append(features)\n",
    "    return np.array(list_of_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T07:02:14.805360Z",
     "start_time": "2020-07-13T07:02:05.525961Z"
    }
   },
   "outputs": [],
   "source": [
    "N = 64 #样本数\n",
    "f_s = 50 #采样频率\n",
    "denominator = 10\n",
    "features2 = extract_features2(\n",
    "    signals, N, f_s, denominator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T07:02:14.815325Z",
     "start_time": "2020-07-13T07:02:14.807346Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4088, 36)\n",
      "(4088, 90)\n",
      "(4088, 126)\n"
     ]
    }
   ],
   "source": [
    "print(features1.shape)\n",
    "print(features2.shape)\n",
    "features = np.hstack((features1,features2))\n",
    "print(features.shape)\n",
    "labels = np.array(anomalyType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T07:02:14.850269Z",
     "start_time": "2020-07-13T07:02:14.817318Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04683592, 0.25036444, 0.25036444, ..., 0.11743982, 0.07147435,\n",
       "        0.08730024],\n",
       "       [0.04524433, 0.18591063, 0.18591063, ..., 0.07092869, 0.07071514,\n",
       "        0.05796451],\n",
       "       [0.04647946, 0.21345474, 0.21345474, ..., 0.06976539, 0.03048049,\n",
       "        0.02446915],\n",
       "       ...,\n",
       "       [0.03630003, 0.09702208, 0.09702208, ..., 0.51388521, 0.12363135,\n",
       "        0.11689472],\n",
       "       [0.0431912 , 0.17840832, 0.17840832, ..., 0.13557564, 0.07576014,\n",
       "        0.0422648 ],\n",
       "       [0.05485486, 0.17418917, 0.17418917, ..., 0.07023594, 0.01174558,\n",
       "        0.00096844]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StandardScaler().fit_transform(features)\n",
    "Normalizer().fit_transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 信号分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T07:02:14.856225Z",
     "start_time": "2020-07-13T07:02:14.851228Z"
    }
   },
   "outputs": [],
   "source": [
    "def randomize(features, labels):\n",
    "    permutation = np.random.permutation(labels.shape[0])\n",
    "    shuffled_features = features[permutation, :]\n",
    "    shuffled_labels = labels[permutation]\n",
    "    return shuffled_features, shuffled_labels\n",
    "\n",
    "iteration = 100\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T07:02:33.066766Z",
     "start_time": "2020-07-13T07:02:14.858210Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of Logistic Regression\n",
      "Accuracy on training set is : 0.9609821740650125\n",
      "Accuracy on test set is : 0.9516136919315406\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.965     0.984     0.974    108057\n",
      "         1.0      0.849     0.732     0.787     14261\n",
      "         2.0      0.120     0.068     0.087       382\n",
      "\n",
      "    accuracy                          0.952    122700\n",
      "   macro avg      0.645     0.595     0.616    122700\n",
      "weighted avg      0.949     0.952     0.950    122700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yTest, yPredict = [], []\n",
    "trainingScore, testingScore = 0, 0\n",
    "for i in range(iteration):\n",
    "    X, Y = randomize(features, labels)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        X, Y, test_size=0.3, random_state=0)\n",
    "    clf = LogisticRegression(random_state=0)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    Y_test_pred = clf.predict(X_test)\n",
    "    yTest.extend(Y_test)\n",
    "    yPredict.extend(Y_test_pred)\n",
    "    trainingScore += clf.score(X_train, Y_train)\n",
    "    testingScore += clf.score(X_test, Y_test)\n",
    "print(\"Results of Logistic Regression\")\n",
    "print(\"Accuracy on training set is : {}\".format(trainingScore/iteration))\n",
    "print(\"Accuracy on test set is : {}\".format(testingScore/iteration))\n",
    "print(classification_report(yTest, yPredict, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T07:03:24.924012Z",
     "start_time": "2020-07-13T07:02:33.067763Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of Support Vector Machine\n",
      "Accuracy on training set is : 0.951237329605033\n",
      "Accuracy on test set is : 0.9480603096984512\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.952     0.992     0.971    108056\n",
      "         1.0      0.906     0.641     0.751     14274\n",
      "         2.0      0.000     0.000     0.000       370\n",
      "\n",
      "    accuracy                          0.948    122700\n",
      "   macro avg      0.619     0.544     0.574    122700\n",
      "weighted avg      0.944     0.948     0.943    122700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yTest, yPredict = [], []\n",
    "trainingScore, testingScore = 0, 0\n",
    "for i in range(iteration):\n",
    "    X, Y = randomize(features, labels)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        X, Y, test_size=0.3, random_state=0)\n",
    "    clf = svm.SVC()\n",
    "    clf.fit(X_train, Y_train)\n",
    "    Y_test_pred = clf.predict(X_test)\n",
    "    yTest.extend(Y_test)\n",
    "    yPredict.extend(Y_test_pred)\n",
    "    trainingScore += clf.score(X_train, Y_train)\n",
    "    testingScore += clf.score(X_test, Y_test)\n",
    "print(\"Results of Support Vector Machine\")\n",
    "print(\"Accuracy on training set is : {}\".format(trainingScore/iteration))\n",
    "print(\"Accuracy on test set is : {}\".format(testingScore/iteration))\n",
    "print(classification_report(yTest, yPredict, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T07:16:01.417756Z",
     "start_time": "2020-07-13T07:13:02.082744Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of RandomForest\n",
      "Accuracy on training set is : 0.999982523593149\n",
      "Accuracy on test set is : 0.9560146699266506\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.964     0.988     0.976    108002\n",
      "         1.0      0.886     0.741     0.807     14288\n",
      "         2.0      0.000     0.000     0.000       410\n",
      "\n",
      "    accuracy                          0.956    122700\n",
      "   macro avg      0.616     0.576     0.594    122700\n",
      "weighted avg      0.951     0.956     0.953    122700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yTest, yPredict = [], []\n",
    "trainingScore, testingScore = 0, 0\n",
    "for i in range(iteration):\n",
    "    X, Y = randomize(features, labels)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        X, Y, test_size=0.3, random_state=0)\n",
    "    clf = RandomForestClassifier(n_estimators=100)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    Y_test_pred = clf.predict(X_test)\n",
    "    yTest.extend(Y_test)\n",
    "    yPredict.extend(Y_test_pred)\n",
    "    trainingScore += clf.score(X_train, Y_train)\n",
    "    testingScore += clf.score(X_test, Y_test)\n",
    "print(\"Results of RandomForest\")\n",
    "print(\"Accuracy on training set is : {}\".format(trainingScore/iteration))\n",
    "print(\"Accuracy on test set is : {}\".format(testingScore/iteration))\n",
    "print(classification_report(yTest, yPredict, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 跨数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T07:06:42.630874Z",
     "start_time": "2020-07-13T07:06:23.633369Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of Logistic Reg\n",
      "Test Results of Poor Road\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.942     0.995     0.968     24644\n",
      "         1.0      0.762     0.360     0.489      2042\n",
      "         2.0      0.174     0.041     0.067       389\n",
      "\n",
      "    accuracy                          0.933     27075\n",
      "   macro avg      0.626     0.465     0.508     27075\n",
      "weighted avg      0.918     0.933     0.919     27075\n",
      "\n",
      "Test Results of Bad Road\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.973     0.980     0.977     83568\n",
      "         1.0      0.856     0.807     0.831     12057\n",
      "         2.0      0.000     0.000     0.000         0\n",
      "\n",
      "    accuracy                          0.958     95625\n",
      "   macro avg      0.610     0.596     0.603     95625\n",
      "weighted avg      0.959     0.958     0.958     95625\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iteration = 100\n",
    "yTestPoor, yPredictPoor = [], []\n",
    "yTestBad, yPredictBad = [], []\n",
    "trainingScore, testingScore = 0, 0\n",
    "for i in range(iteration):\n",
    "    permutation = np.random.permutation(features.shape[0])\n",
    "    X = features[permutation, :]\n",
    "    Y = dataLabel[permutation, :]\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        X, Y, test_size=0.3, random_state=0)\n",
    "    clf = LogisticRegression(random_state=0)\n",
    "    clf.fit(X_train, Y_train[:, 0])\n",
    "    # 分割测试集为分别来自bad和poor的测试集\n",
    "    X_test_poor, Y_test_poor, X_test_bad, Y_test_bad = [], [], [], []\n",
    "    for idx in range(X_test.shape[0]):\n",
    "        if Y_test[idx][2] == 1:\n",
    "            X_test_poor.append(X_test[idx, :])\n",
    "            Y_test_poor.append(Y_test[idx, :])\n",
    "        else:\n",
    "            X_test_bad.append(X_test[idx, :])\n",
    "            Y_test_bad.append(Y_test[idx, :])\n",
    "    # poor\n",
    "    X_test_poor = np.array(X_test_poor)\n",
    "    Y_test_poor = np.array(Y_test_poor)\n",
    "    Y_test_poor_pred = clf.predict(X_test_poor)\n",
    "    yTestPoor.extend(Y_test_poor[:, 0])\n",
    "    yPredictPoor.extend(Y_test_poor_pred)\n",
    "    # bad\n",
    "    X_test_bad = np.array(X_test_bad)\n",
    "    Y_test_bad = np.array(Y_test_bad)\n",
    "    Y_test_bad_pred = clf.predict(X_test_bad)\n",
    "    yTestBad.extend(Y_test_bad[:, 0])\n",
    "    yPredictBad.extend(Y_test_bad_pred)\n",
    "\n",
    "print(\"Results of Logistic Reg\")\n",
    "print(\"Test Results of Poor Road\")\n",
    "print(classification_report(yTestPoor, yPredictPoor, digits=3))\n",
    "print(\"Test Results of Bad Road\")\n",
    "print(classification_report(yTestBad, yPredictBad, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T07:07:12.030567Z",
     "start_time": "2020-07-13T07:06:42.631905Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of Support Vector Machine\n",
      "Test Results of Poor Road\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.922     0.999     0.959     24257\n",
      "         1.0      0.791     0.167     0.275      2088\n",
      "         2.0      0.000     0.000     0.000       377\n",
      "\n",
      "    accuracy                          0.920     26722\n",
      "   macro avg      0.571     0.388     0.411     26722\n",
      "weighted avg      0.899     0.920     0.892     26722\n",
      "\n",
      "Test Results of Bad Road\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.960     0.989     0.975     83701\n",
      "         1.0      0.909     0.722     0.805     12277\n",
      "\n",
      "    accuracy                          0.955     95978\n",
      "   macro avg      0.934     0.856     0.890     95978\n",
      "weighted avg      0.954     0.955     0.953     95978\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iteration = 100\n",
    "yTestPoor, yPredictPoor = [], []\n",
    "yTestBad, yPredictBad = [], []\n",
    "trainingScore, testingScore = 0, 0\n",
    "for i in range(iteration):\n",
    "    permutation = np.random.permutation(features.shape[0])\n",
    "    X = features[permutation, :]\n",
    "    Y = dataLabel[permutation, :]\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        X, Y, test_size=0.3, random_state=0)\n",
    "    clf = svm.SVC()\n",
    "    clf.fit(X_train, Y_train[:, 0])\n",
    "    # 分割测试集为分别来自bad和poor的测试集\n",
    "    X_test_poor, Y_test_poor, X_test_bad, Y_test_bad = [], [], [], []\n",
    "    for idx in range(X_test.shape[0]):\n",
    "        if Y_test[idx][2] == 1:\n",
    "            X_test_poor.append(X_test[idx, :])\n",
    "            Y_test_poor.append(Y_test[idx, :])\n",
    "        else:\n",
    "            X_test_bad.append(X_test[idx, :])\n",
    "            Y_test_bad.append(Y_test[idx, :])\n",
    "    # poor\n",
    "    X_test_poor = np.array(X_test_poor)\n",
    "    Y_test_poor = np.array(Y_test_poor)\n",
    "    Y_test_poor_pred = clf.predict(X_test_poor)\n",
    "    yTestPoor.extend(Y_test_poor[:, 0])\n",
    "    yPredictPoor.extend(Y_test_poor_pred)\n",
    "    # bad\n",
    "    X_test_bad = np.array(X_test_bad)\n",
    "    Y_test_bad = np.array(Y_test_bad)\n",
    "    Y_test_bad_pred = clf.predict(X_test_bad)\n",
    "    yTestBad.extend(Y_test_bad[:, 0])\n",
    "    yPredictBad.extend(Y_test_bad_pred)\n",
    "\n",
    "print(\"Results of Support Vector Machine\")\n",
    "print(\"Test Results of Poor Road\")\n",
    "print(classification_report(yTestPoor, yPredictPoor, digits=3))\n",
    "print(\"Test Results of Bad Road\")\n",
    "print(classification_report(yTestBad, yPredictBad, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T07:07:30.557978Z",
     "start_time": "2020-07-13T07:07:12.032567Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of RandomForest\n",
      "Test Results of Poor Road\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.928     0.998     0.962     24540\n",
      "         1.0      0.788     0.240     0.368      2096\n",
      "         2.0      0.333     0.003     0.005       383\n",
      "\n",
      "    accuracy                          0.925     27019\n",
      "   macro avg      0.683     0.413     0.445     27019\n",
      "weighted avg      0.909     0.925     0.902     27019\n",
      "\n",
      "Test Results of Bad Road\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.971     0.984     0.977     83446\n",
      "         1.0      0.881     0.797     0.837     12235\n",
      "         2.0      0.000     0.000     0.000         0\n",
      "\n",
      "    accuracy                          0.960     95681\n",
      "   macro avg      0.617     0.594     0.605     95681\n",
      "weighted avg      0.959     0.960     0.959     95681\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iteration = 100\n",
    "yTestPoor, yPredictPoor = [], []\n",
    "yTestBad, yPredictBad = [], []\n",
    "trainingScore, testingScore = 0, 0\n",
    "for i in range(iteration):\n",
    "    permutation = np.random.permutation(features.shape[0])\n",
    "    X = features[permutation, :]\n",
    "    Y = dataLabel[permutation, :]\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        X, Y, test_size=0.3, random_state=0)\n",
    "    clf =RandomForestClassifier(n_estimators=10)\n",
    "    clf.fit(X_train, Y_train[:, 0])\n",
    "    # 分割测试集为分别来自bad和poor的测试集\n",
    "    X_test_poor, Y_test_poor, X_test_bad, Y_test_bad = [], [], [], []\n",
    "    for idx in range(X_test.shape[0]):\n",
    "        if Y_test[idx][2] == 1:\n",
    "            X_test_poor.append(X_test[idx, :])\n",
    "            Y_test_poor.append(Y_test[idx, :])\n",
    "        else:\n",
    "            X_test_bad.append(X_test[idx, :])\n",
    "            Y_test_bad.append(Y_test[idx, :])\n",
    "    # poor\n",
    "    X_test_poor = np.array(X_test_poor)\n",
    "    Y_test_poor = np.array(Y_test_poor)\n",
    "    Y_test_poor_pred = clf.predict(X_test_poor)\n",
    "    yTestPoor.extend(Y_test_poor[:, 0])\n",
    "    yPredictPoor.extend(Y_test_poor_pred)\n",
    "    # bad\n",
    "    X_test_bad = np.array(X_test_bad)\n",
    "    Y_test_bad = np.array(Y_test_bad)\n",
    "    Y_test_bad_pred = clf.predict(X_test_bad)\n",
    "    yTestBad.extend(Y_test_bad[:, 0])\n",
    "    yPredictBad.extend(Y_test_bad_pred)\n",
    "\n",
    "print(\"Results of RandomForest\")\n",
    "print(\"Test Results of Poor Road\")\n",
    "print(classification_report(yTestPoor, yPredictPoor, digits=3))\n",
    "print(\"Test Results of Bad Road\")\n",
    "print(classification_report(yTestBad, yPredictBad, digits=3))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.181px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
