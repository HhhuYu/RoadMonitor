{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T13:32:16.207958Z",
     "start_time": "2020-07-07T13:32:16.200975Z"
    }
   },
   "outputs": [],
   "source": [
    "from siml.sk_utils import *\n",
    "from siml.signal_analysis_utils import *\n",
    "import numpy as np\n",
    "import pywt\n",
    "import scipy.stats\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载数据文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T13:32:16.231922Z",
     "start_time": "2020-07-07T13:32:16.227939Z"
    }
   },
   "outputs": [],
   "source": [
    "typeDescription = {\n",
    "    0: 'normal',\n",
    "    1: 'pothole',\n",
    "    2: 'transverse',\n",
    "}\n",
    "\n",
    "\n",
    "def readFile(filename):\n",
    "    return np.loadtxt(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T13:32:16.847820Z",
     "start_time": "2020-07-07T13:32:16.233887Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集： (4088, 64, 3)\n",
      "{'normal': 3601, 'pothole': 474, 'transverse': 13}\n"
     ]
    }
   ],
   "source": [
    "folderPath = '../../data/Final_Version/all/datasets/'\n",
    "dataFile = ['dataX.txt', 'dataY.txt', 'dataZ.txt']\n",
    "labelFile = ['dataLabel.txt']\n",
    "\n",
    "signals = []\n",
    "for file in dataFile:\n",
    "    dataPath = folderPath+file\n",
    "    signals.append(np.loadtxt(dataPath))\n",
    "signals = np.transpose(np.array(signals), (1, 2, 0))\n",
    "print('数据集：', signals.shape)\n",
    "\n",
    "labelFilePath = folderPath+labelFile[0]\n",
    "dataLabel = np.loadtxt(labelFilePath)\n",
    "anomalyType = list(dataLabel[:, 0])\n",
    "\n",
    "dic = {}\n",
    "temp = Counter(anomalyType)\n",
    "for key in temp.keys():\n",
    "    dic[typeDescription[key]] = temp[key]\n",
    "print(dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征提取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 时域特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T13:32:16.859792Z",
     "start_time": "2020-07-07T13:32:16.849783Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_entropy(list_values):\n",
    "    counter_values = Counter(list_values).most_common()\n",
    "    # print(counter_values)\n",
    "    probabilities = [elem[1]/len(list_values) for elem in counter_values]\n",
    "    # print(probabilities)\n",
    "    entropy = scipy.stats.entropy(probabilities)\n",
    "    return entropy\n",
    "\n",
    "\n",
    "def calculate_statistics(list_values):\n",
    "    n5 = np.nanpercentile(list_values, 5)\n",
    "    n25 = np.nanpercentile(list_values, 25)\n",
    "    n75 = np.nanpercentile(list_values, 75)\n",
    "    n95 = np.nanpercentile(list_values, 95)\n",
    "    median = np.nanpercentile(list_values, 50)\n",
    "    mean = np.nanmean(list_values)\n",
    "    std = np.nanstd(list_values)\n",
    "    var = np.nanvar(list_values)\n",
    "    rms = np.nanmean(np.sqrt(list_values**2))\n",
    "    return [n5, n25, n75, n95, median, mean, std, var, rms]\n",
    "\n",
    "\n",
    "def calculate_crossings(list_values):\n",
    "    zero_crossing_indices = np.nonzero(np.diff(np.array(list_values) > 0))[0]\n",
    "    no_zero_crossings = len(zero_crossing_indices)\n",
    "    mean_crossing_indices = np.nonzero(\n",
    "        np.diff(np.array(list_values) > np.nanmean(list_values)))[0]\n",
    "    no_mean_crossings = len(mean_crossing_indices)\n",
    "    return [no_zero_crossings, no_mean_crossings]\n",
    "\n",
    "\n",
    "def get_features(list_values):\n",
    "    entropy = calculate_entropy(list_values)\n",
    "    crossings = calculate_crossings(list_values)\n",
    "    statistics = calculate_statistics(list_values)\n",
    "    return [entropy] + crossings + statistics\n",
    "\n",
    "\n",
    "def extract_features1(dataset):\n",
    "    uci_har_features = []\n",
    "    for signal_no in range(0, len(dataset)):\n",
    "        features = []\n",
    "        for signal_comp in range(0, dataset.shape[2]):\n",
    "            signal = dataset[signal_no, :, signal_comp]\n",
    "            features += get_features(signal)\n",
    "        uci_har_features.append(features)\n",
    "    X = np.array(uci_har_features)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T13:32:27.145523Z",
     "start_time": "2020-07-07T13:32:16.861751Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "features1 = extract_features1(signals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 频域特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T13:32:27.153493Z",
     "start_time": "2020-07-07T13:32:27.146511Z"
    }
   },
   "outputs": [],
   "source": [
    "#FFT\n",
    "def get_fft_values(y_values, N, f_s):\n",
    "    f_values = np.linspace(0.0, f_s/2.0, N//2)\n",
    "    fft_values_ = fft(y_values)\n",
    "    fft_values = 2.0/N * np.abs(fft_values_[0:N//2])\n",
    "    return fft_values\n",
    "\n",
    "#PSD\n",
    "def get_psd_values(y_values, N, f_s):\n",
    "    f_values, psd_values = welch(y_values, fs=f_s)\n",
    "    return  psd_values\n",
    "\n",
    "#Autocorrelation\n",
    "def autocorr(x):\n",
    "    result = np.correlate(x, x, mode='full')\n",
    "    return result[len(result)//2:]\n",
    " \n",
    "def get_autocorr_values(y_values, N, f_s):\n",
    "    autocorr_values = autocorr(y_values)\n",
    "    x_values = np.array([ 1.0*jj/f_s for jj in range(0, N)])\n",
    "    return autocorr_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T13:32:27.167485Z",
     "start_time": "2020-07-07T13:32:27.156007Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_features2(dataset, N, f_s):\n",
    "    uci_har_features = []\n",
    "    for signal_no in range(0, len(dataset)):\n",
    "        features = []\n",
    "        for signal_comp in range(0, dataset.shape[2]):\n",
    "            signal = dataset[signal_no, :, signal_comp]\n",
    "            features += get_features(get_fft_values(signal, N, f_s))\n",
    "            features += get_features(get_psd_values(signal, N, f_s))\n",
    "            features += get_features(get_autocorr_values(signal, N, f_s))\n",
    "        uci_har_features.append(features)\n",
    "    X = np.array(uci_har_features)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T13:33:01.969235Z",
     "start_time": "2020-07-07T13:32:27.170477Z"
    }
   },
   "outputs": [],
   "source": [
    "N = 64 #样本数\n",
    "f_s = 50 #采样频率\n",
    "features2 = extract_features2(\n",
    "    signals, N, f_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T13:33:01.983198Z",
     "start_time": "2020-07-07T13:33:01.971230Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4088, 36)\n",
      "(4088, 108)\n",
      "(4088, 144)\n"
     ]
    }
   ],
   "source": [
    "print(features1.shape)\n",
    "print(features2.shape)\n",
    "features = np.hstack((features1,features2))\n",
    "print(features.shape)\n",
    "labels = np.array(anomalyType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T13:33:02.021096Z",
     "start_time": "2020-07-07T13:33:01.986191Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03575385, 0.19112452, 0.19112452, ..., 0.07460356, 0.64065675,\n",
       "        0.04425083],\n",
       "       [0.03739319, 0.15365001, 0.15365001, ..., 0.06892976, 0.52569022,\n",
       "        0.03518355],\n",
       "       [0.04312016, 0.19802731, 0.19802731, ..., 0.05407852, 0.28059378,\n",
       "        0.02499524],\n",
       "       ...,\n",
       "       [0.0051629 , 0.0137993 , 0.0137993 , ..., 0.03522252, 0.9889549 ,\n",
       "        0.02238954],\n",
       "       [0.02768039, 0.11433838, 0.11433838, ..., 0.07276565, 0.78724462,\n",
       "        0.03910679],\n",
       "       [0.04581059, 0.14546949, 0.14546949, ..., 0.08898191, 0.70757898,\n",
       "        0.05596641]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StandardScaler().fit_transform(features)\n",
    "Normalizer().fit_transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 信号分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T13:33:02.027082Z",
     "start_time": "2020-07-07T13:33:02.022093Z"
    }
   },
   "outputs": [],
   "source": [
    "def randomize(features, labels):\n",
    "    permutation = np.random.permutation(labels.shape[0])\n",
    "    shuffled_features = features[permutation, :]\n",
    "    shuffled_labels = labels[permutation]\n",
    "    return shuffled_features, shuffled_labels\n",
    "\n",
    "iteration = 100\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T13:33:24.770453Z",
     "start_time": "2020-07-07T13:33:02.029076Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of Logistic Regression\n",
      "Accuracy on training set is : 0.9566340440405453\n",
      "Accuracy on test set is : 0.9536430317848418\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.963     0.986     0.975    108016\n",
      "         1.0      0.871     0.732     0.795     14293\n",
      "         2.0      0.000     0.000     0.000       391\n",
      "\n",
      "    accuracy                          0.954    122700\n",
      "   macro avg      0.611     0.573     0.590    122700\n",
      "weighted avg      0.949     0.954     0.951    122700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yTest, yPredict = [], []\n",
    "trainingScore, testingScore = 0, 0\n",
    "for i in range(iteration):\n",
    "    X, Y = randomize(features, labels)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        X, Y, test_size=0.3, random_state=0)\n",
    "    clf = LogisticRegression(random_state=0)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    Y_test_pred = clf.predict(X_test)\n",
    "    yTest.extend(Y_test)\n",
    "    yPredict.extend(Y_test_pred)\n",
    "    trainingScore += clf.score(X_train, Y_train)\n",
    "    testingScore += clf.score(X_test, Y_test)\n",
    "print(\"Results of Logistic Regression\")\n",
    "print(\"Accuracy on training set is : {}\".format(trainingScore/iteration))\n",
    "print(\"Accuracy on test set is : {}\".format(testingScore/iteration))\n",
    "print(classification_report(yTest, yPredict, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T13:34:21.908140Z",
     "start_time": "2020-07-07T13:33:24.771452Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of Support Vector Machine\n",
      "Accuracy on training set is : 0.9467458930443907\n",
      "Accuracy on test set is : 0.9438549307253464\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.945     0.994     0.969    107922\n",
      "         1.0      0.929     0.594     0.724     14334\n",
      "         2.0      0.000     0.000     0.000       444\n",
      "\n",
      "    accuracy                          0.944    122700\n",
      "   macro avg      0.625     0.529     0.564    122700\n",
      "weighted avg      0.940     0.944     0.937    122700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yTest, yPredict = [], []\n",
    "trainingScore, testingScore = 0, 0\n",
    "for i in range(iteration):\n",
    "    X, Y = randomize(features, labels)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        X, Y, test_size=0.3, random_state=0)\n",
    "    clf = svm.SVC()\n",
    "    clf.fit(X_train, Y_train)\n",
    "    Y_test_pred = clf.predict(X_test)\n",
    "    yTest.extend(Y_test)\n",
    "    yPredict.extend(Y_test_pred)\n",
    "    trainingScore += clf.score(X_train, Y_train)\n",
    "    testingScore += clf.score(X_test, Y_test)\n",
    "print(\"Results of Support Vector Machine\")\n",
    "print(\"Accuracy on training set is : {}\".format(trainingScore/iteration))\n",
    "print(\"Accuracy on test set is : {}\".format(testingScore/iteration))\n",
    "print(classification_report(yTest, yPredict, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T13:59:04.258612Z",
     "start_time": "2020-07-07T13:55:42.565012Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of RandomForest\n",
      "Accuracy on training set is : 0.9999720377490386\n",
      "Accuracy on test set is : 0.9557946210268947\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.965     0.987     0.976    108062\n",
      "         1.0      0.874     0.749     0.807     14239\n",
      "         2.0      0.000     0.000     0.000       399\n",
      "\n",
      "    accuracy                          0.956    122700\n",
      "   macro avg      0.613     0.579     0.594    122700\n",
      "weighted avg      0.951     0.956     0.953    122700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yTest, yPredict = [], []\n",
    "trainingScore, testingScore = 0, 0\n",
    "for i in range(iteration):\n",
    "    X, Y = randomize(features, labels)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        X, Y, test_size=0.3, random_state=0)\n",
    "    clf = RandomForestClassifier(n_estimators=100)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    Y_test_pred = clf.predict(X_test)\n",
    "    yTest.extend(Y_test)\n",
    "    yPredict.extend(Y_test_pred)\n",
    "    trainingScore += clf.score(X_train, Y_train)\n",
    "    testingScore += clf.score(X_test, Y_test)\n",
    "print(\"Results of RandomForest\")\n",
    "print(\"Accuracy on training set is : {}\".format(trainingScore/iteration))\n",
    "print(\"Accuracy on test set is : {}\".format(testingScore/iteration))\n",
    "print(classification_report(yTest, yPredict, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 跨数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T14:10:45.677400Z",
     "start_time": "2020-07-07T14:10:22.516559Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of Logistic Reg\n",
      "Test Results of Poor Road\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.936     0.998     0.966     24615\n",
      "         1.0      0.825     0.331     0.472      2088\n",
      "         2.0      0.000     0.000     0.000       374\n",
      "\n",
      "    accuracy                          0.933     27077\n",
      "   macro avg      0.587     0.443     0.479     27077\n",
      "weighted avg      0.915     0.933     0.915     27077\n",
      "\n",
      "Test Results of Bad Road\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.971     0.983     0.977     83458\n",
      "         1.0      0.872     0.799     0.834     12165\n",
      "         2.0      0.000     0.000     0.000         0\n",
      "\n",
      "    accuracy                          0.959     95623\n",
      "   macro avg      0.614     0.594     0.604     95623\n",
      "weighted avg      0.959     0.959     0.959     95623\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iteration = 100\n",
    "yTestPoor, yPredictPoor = [], []\n",
    "yTestBad, yPredictBad = [], []\n",
    "trainingScore, testingScore = 0, 0\n",
    "for i in range(iteration):\n",
    "    permutation = np.random.permutation(features.shape[0])\n",
    "    X = features[permutation, :]\n",
    "    Y = dataLabel[permutation, :]\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        X, Y, test_size=0.3, random_state=0)\n",
    "    clf = LogisticRegression(random_state=0)\n",
    "    clf.fit(X_train, Y_train[:, 0])\n",
    "    # 分割测试集为分别来自bad和poor的测试集\n",
    "    X_test_poor, Y_test_poor, X_test_bad, Y_test_bad = [], [], [], []\n",
    "    for idx in range(X_test.shape[0]):\n",
    "        if Y_test[idx][2] == 1:\n",
    "            X_test_poor.append(X_test[idx, :])\n",
    "            Y_test_poor.append(Y_test[idx, :])\n",
    "        else:\n",
    "            X_test_bad.append(X_test[idx, :])\n",
    "            Y_test_bad.append(Y_test[idx, :])\n",
    "    # poor\n",
    "    X_test_poor = np.array(X_test_poor)\n",
    "    Y_test_poor = np.array(Y_test_poor)\n",
    "    Y_test_poor_pred = clf.predict(X_test_poor)\n",
    "    yTestPoor.extend(Y_test_poor[:, 0])\n",
    "    yPredictPoor.extend(Y_test_poor_pred)\n",
    "    # bad\n",
    "    X_test_bad = np.array(X_test_bad)\n",
    "    Y_test_bad = np.array(Y_test_bad)\n",
    "    Y_test_bad_pred = clf.predict(X_test_bad)\n",
    "    yTestBad.extend(Y_test_bad[:, 0])\n",
    "    yPredictBad.extend(Y_test_bad_pred)\n",
    "\n",
    "print(\"Results of Logistic Reg\")\n",
    "print(\"Test Results of Poor Road\")\n",
    "print(classification_report(yTestPoor, yPredictPoor, digits=3))\n",
    "print(\"Test Results of Bad Road\")\n",
    "print(classification_report(yTestBad, yPredictBad, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T14:11:18.136703Z",
     "start_time": "2020-07-07T14:10:45.838966Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of Support Vector Machine\n",
      "Test Results of Poor Road\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.915     1.000     0.956     24535\n",
      "         1.0      0.867     0.093     0.168      2103\n",
      "         2.0      0.000     0.000     0.000       390\n",
      "\n",
      "    accuracy                          0.915     27028\n",
      "   macro avg      0.594     0.364     0.375     27028\n",
      "weighted avg      0.898     0.915     0.881     27028\n",
      "\n",
      "Test Results of Bad Road\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.956     0.993     0.974     83610\n",
      "         1.0      0.934     0.687     0.791     12062\n",
      "\n",
      "    accuracy                          0.954     95672\n",
      "   macro avg      0.945     0.840     0.883     95672\n",
      "weighted avg      0.954     0.954     0.951     95672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iteration = 100\n",
    "yTestPoor, yPredictPoor = [], []\n",
    "yTestBad, yPredictBad = [], []\n",
    "trainingScore, testingScore = 0, 0\n",
    "for i in range(iteration):\n",
    "    permutation = np.random.permutation(features.shape[0])\n",
    "    X = features[permutation, :]\n",
    "    Y = dataLabel[permutation, :]\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        X, Y, test_size=0.3, random_state=0)\n",
    "    clf = svm.SVC()\n",
    "    clf.fit(X_train, Y_train[:, 0])\n",
    "    # 分割测试集为分别来自bad和poor的测试集\n",
    "    X_test_poor, Y_test_poor, X_test_bad, Y_test_bad = [], [], [], []\n",
    "    for idx in range(X_test.shape[0]):\n",
    "        if Y_test[idx][2] == 1:\n",
    "            X_test_poor.append(X_test[idx, :])\n",
    "            Y_test_poor.append(Y_test[idx, :])\n",
    "        else:\n",
    "            X_test_bad.append(X_test[idx, :])\n",
    "            Y_test_bad.append(Y_test[idx, :])\n",
    "    # poor\n",
    "    X_test_poor = np.array(X_test_poor)\n",
    "    Y_test_poor = np.array(Y_test_poor)\n",
    "    Y_test_poor_pred = clf.predict(X_test_poor)\n",
    "    yTestPoor.extend(Y_test_poor[:, 0])\n",
    "    yPredictPoor.extend(Y_test_poor_pred)\n",
    "    # bad\n",
    "    X_test_bad = np.array(X_test_bad)\n",
    "    Y_test_bad = np.array(Y_test_bad)\n",
    "    Y_test_bad_pred = clf.predict(X_test_bad)\n",
    "    yTestBad.extend(Y_test_bad[:, 0])\n",
    "    yPredictBad.extend(Y_test_bad_pred)\n",
    "\n",
    "print(\"Results of Support Vector Machine\")\n",
    "print(\"Test Results of Poor Road\")\n",
    "print(classification_report(yTestPoor, yPredictPoor, digits=3))\n",
    "print(\"Test Results of Bad Road\")\n",
    "print(classification_report(yTestBad, yPredictBad, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T14:03:16.199409Z",
     "start_time": "2020-07-07T14:00:00.217421Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of RandomForest\n",
      "Test Results of Poor Road\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.931     0.998     0.963     24679\n",
      "         1.0      0.819     0.266     0.402      2044\n",
      "         2.0      0.000     0.000     0.000       399\n",
      "\n",
      "    accuracy                          0.928     27122\n",
      "   macro avg      0.583     0.421     0.455     27122\n",
      "weighted avg      0.909     0.928     0.907     27122\n",
      "\n",
      "Test Results of Bad Road\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0      0.975     0.984     0.980     83298\n",
      "         1.0      0.885     0.828     0.856     12280\n",
      "\n",
      "    accuracy                          0.964     95578\n",
      "   macro avg      0.930     0.906     0.918     95578\n",
      "weighted avg      0.963     0.964     0.964     95578\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iteration = 100\n",
    "yTestPoor, yPredictPoor = [], []\n",
    "yTestBad, yPredictBad = [], []\n",
    "trainingScore, testingScore = 0, 0\n",
    "for i in range(iteration):\n",
    "    permutation = np.random.permutation(features.shape[0])\n",
    "    X = features[permutation, :]\n",
    "    Y = dataLabel[permutation, :]\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        X, Y, test_size=0.3, random_state=0)\n",
    "    clf =RandomForestClassifier(n_estimators=100)\n",
    "    clf.fit(X_train, Y_train[:, 0])\n",
    "    # 分割测试集为分别来自bad和poor的测试集\n",
    "    X_test_poor, Y_test_poor, X_test_bad, Y_test_bad = [], [], [], []\n",
    "    for idx in range(X_test.shape[0]):\n",
    "        if Y_test[idx][2] == 1:\n",
    "            X_test_poor.append(X_test[idx, :])\n",
    "            Y_test_poor.append(Y_test[idx, :])\n",
    "        else:\n",
    "            X_test_bad.append(X_test[idx, :])\n",
    "            Y_test_bad.append(Y_test[idx, :])\n",
    "    # poor\n",
    "    X_test_poor = np.array(X_test_poor)\n",
    "    Y_test_poor = np.array(Y_test_poor)\n",
    "    Y_test_poor_pred = clf.predict(X_test_poor)\n",
    "    yTestPoor.extend(Y_test_poor[:, 0])\n",
    "    yPredictPoor.extend(Y_test_poor_pred)\n",
    "    # bad\n",
    "    X_test_bad = np.array(X_test_bad)\n",
    "    Y_test_bad = np.array(Y_test_bad)\n",
    "    Y_test_bad_pred = clf.predict(X_test_bad)\n",
    "    yTestBad.extend(Y_test_bad[:, 0])\n",
    "    yPredictBad.extend(Y_test_bad_pred)\n",
    "\n",
    "print(\"Results of RandomForest\")\n",
    "print(\"Test Results of Poor Road\")\n",
    "print(classification_report(yTestPoor, yPredictPoor, digits=3))\n",
    "print(\"Test Results of Bad Road\")\n",
    "print(classification_report(yTestBad, yPredictBad, digits=3))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.194px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
